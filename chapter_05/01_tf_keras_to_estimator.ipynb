{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=7, micro=4, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.2\n",
      "numpy 1.17.4\n",
      "pandas 0.25.3\n",
      "sklearn 0.22\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = './data/train.csv'\n",
    "eval_file = './data/eval.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3  female  35.0                   1      0  53.1000  First        C   \n",
      "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
      "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
      "1    male  54.0                   0      0  51.8625   First        E   \n",
      "2  female  58.0                   0      0  26.5500   First        C   \n",
      "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
      "4    male  34.0                   0      0  13.0000  Second        D   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "2  Southampton     y  \n",
      "3  Southampton     y  \n",
      "4  Southampton     y  \n"
     ]
    }
   ],
   "source": [
    "y_train = train_df.pop('survived')\n",
    "y_eval = eval_df.pop('survived')\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 9) (264, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, eval_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13b961b90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.age.hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13fd92dd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.sex.value_counts().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13fdf0c10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAN3ElEQVR4nO3dfYxld13H8ffHbbuALa3QDW4KOm3daEqhS7soaEVEVKBqQaugRhtjsongA38YXdKEVCPJIj4gpEhK5KlUqCJEQjUCQsGgtu7WfSpQWukaWQtNa1oo1irr1z/u2TKMc7/7NDPn3un7ldzsmd85c+czv3t3Pvs75+7cVBWSJE3zDWMHkCTNNotCktSyKCRJLYtCktSyKCRJrVPGDrCSzj777FpYWBg7hiTNld27d99bVZum7V9XRbGwsMCuXbvGjiFJcyXJv3b7PfUkSWpZFJKklkUhSWpZFJKklkUhSWpZFJKklkUhSWpZFJKklkUhSWpZFJKklkUhSWpZFJKklkUhSWpZFJKklkUhSWpZFJKk1rp646L9hx5gYceNY8fQKji487KxI0iPWq4oJEkti0KS1LIoJEkti0KS1LIoJEkti0KS1LIoJEkti0KS1LIoJEkti0KS1LIoJEkti0KS1LIoJEkti0KS1DqmokhyVZLbkuxLsifJd612sCVf/7lJPriWX1OSNHHU96NI8mzgR4CLq+rhJGcDp616MknSTDiWFcVm4N6qehigqu6tqn9PckmSjyfZneRvkmwGSPJtST6SZG+SW5Ocn4nXJTmQZH+Slw7HPjfJTUnem+QzSa5PkmHfC4axW4EfX6XvX5J0FMdSFB8CnpLks0nelOT7kpwKvBG4oqouAd4KvGY4/nrgmqq6CPhu4G4mP+i3AhcBzwded6RYgGcArwQuAM4DvifJY4C3AD8KXAJ888l/q5KkE3HUU09V9WCSS4DvBb4fuAH4HeBC4MPDAmADcHeSM4Bzqur9w+f+F0CSS4F3V9Vh4ItJPg48E/gScEtVfX44bg+wADwI3FVVdwzj7wK2L5cvyfYj+zY8ftMJTIEkqXNM75k9/IC/CbgpyX7gFcBtVfXsxccNRXG8Hl60ffhYMy3Kdi1wLcDGzVvqBL6+JKlx1FNPSb49yZZFQ1uBTwObhgvdJDk1yVOr6svA55O8eBjfmORxwN8BL02yIckm4DnALc2X/QywkOT84eOfPu7vTJK0Io7lGsXpwDuSfCrJPibXEl4NXAG8NsleYA+T6xEAPwf86nDs3zO5vvB+YB+wF/go8BtV9YVpX3A4ZbUduHG4mH3PiXxzkqSTl6r1c7Zm4+YttfnK148dQ6vg4M7Lxo4grVtJdlfVtmn7/Z/ZkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqTWcb1J0Kx72jlnssvfMipJK8oVhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpdcrYAVbS/kMPsLDjxrFjaB05uPOysSNIo3NFIUlqWRSSpJZFIUlqWRSSpJZFIUlqWRSSpJZFIUlqWRSSpJZFIUlqWRSSpJZFIUlqWRSSpJZFIUlqWRSSpNaqFkWSw0n2LLotJNmW5A3HcR9nJXn5auaUJE232u9H8VBVbV0ydhDYtfTAJKdU1VeXuY+zgJcDb1r5eJKko1nzU09Jnpvkg8P21UmuS/JJ4LokT01yy7D62JdkC7ATOH8Ye91a55WkR7vVXlE8NsmeYfuuqnrJMsdcAFxaVQ8leSPwR1V1fZLTgA3ADuDCZVYmACTZDmwH2PD4TSv/HUjSo9wYp56W+kBVPTRs/wNwVZInA++rqjuStJ9cVdcC1wJs3LylTjawJOnrzcKrnr5yZKOq/hT4MeAh4K+SPG+0VJIkYPVXFMclyXnA56rqDUm+BXg6sBc4Y9xkkvToNQsrisV+CjgwXNe4EHhnVd0HfDLJAS9mS9LaW9UVRVWdvszYTcBNw/bVS/btZPIqp6Wf8zOrElCSdFSztqKQJM0Yi0KS1LIoJEkti0KS1LIoJEkti0KS1LIoJEkti0KS1LIoJEkti0KS1LIoJEkti0KS1JqpXzN+sp52zpns2nnZ2DEkaV1xRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJalkUkqSWRSFJap0ydoCVtP/QAyzsuHHsGJK0pg7uvGxV798VhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIkloWhSSpZVFIklorVhRJnphkz3D7QpJDw/b9ST415XN+O8nzj+G+F5IcWKmskqRjt2LvR1FV9wFbAZJcDTxYVb+XZAH44JTPefVy40k2VNXhlcomSTpxa3XqaUOStyS5LcmHkjwWIMnbk1wxbB9M8toktwI/meSSJHuT7AVesUY5JUlLrFVRbAGuqaqnAvcDPzHluPuq6uKqeg/wNuBXquqiNcooSVrGWhXFXVW1Z9jeDSxMOe4GgCRnAWdV1SeG8eum3XGS7Ul2Jdl1+D8fWKm8kqTBWhXFw4u2DzP92shXjveOq+raqtpWVds2PO7MEwonSZpuJl8eW1X3A/cnuXQY+tkx80jSo9lMFsXgF4BrkuwBMnYYSXq0SlWNnWHFbNy8pTZf+fqxY0jSmjq487KT+vwku6tq27T9s7yikCTNAItCktSyKCRJLYtCktSyKCRJLYtCktSyKCRJLYtCktSyKCRJLYtCktSyKCRJLYtCktSyKCRJrWlvIDSXnnbOmew6yd+iKEn6eq4oJEkti0KS1LIoJEkti0KS1LIoJEkti0KS1LIoJEkti0KS1LIoJEkti0KS1LIoJEkti0KS1LIoJEkti0KS1LIoJEkti0KS1LIoJEmtVNXYGVZMki8Dt4+d4wSdDdw7dogTMK+5wexjmdfs85objp79W6tq07Sd6+qtUIHbq2rb2CFORJJd85h9XnOD2ccyr9nnNTecfHZPPUmSWhaFJKm13ori2rEDnIR5zT6vucHsY5nX7POaG04y+7q6mC1JWnnrbUUhSVphFoUkqbUuiiLJC5LcnuTOJDvGznM0SQ4m2Z9kT5Jdw9gTknw4yR3Dn980dk6AJG9Nck+SA4vGls2aiTcMj8O+JBePl3xq9quTHBrmfk+SFy3a96oh++1Jfnic1JDkKUk+luRTSW5L8mvD+MzPe5N9Hub9MUluSbJ3yP5bw/i5SW4eMt6Q5LRhfOPw8Z3D/oUZy/32JHctmvOtw/jxP1+qaq5vwAbgX4DzgNOAvcAFY+c6SuaDwNlLxn4X2DFs7wBeO3bOIctzgIuBA0fLCrwI+GsgwLOAm2cw+9XAry9z7AXDc2cjcO7wnNowUu7NwMXD9hnAZ4d8Mz/vTfZ5mPcApw/bpwI3D/P5Z8DLhvE3A780bL8cePOw/TLghhnL/XbgimWOP+7ny3pYUXwncGdVfa6q/ht4D3D5yJlOxOXAO4btdwAvHjHLI6rqE8B/LBmelvVy4J018Y/AWUk2r03S/29K9mkuB95TVQ9X1V3AnUyeW2uuqu6uqluH7S8DnwbOYQ7mvck+zSzNe1XVg8OHpw63Ap4HvHcYXzrvRx6P9wI/kCRrFPcRTe5pjvv5sh6K4hzg3xZ9/Hn6J+YsKOBDSXYn2T6MPamq7h62vwA8aZxox2Ra1nl5LH55WHK/ddEpvpnMPpzOeAaTfyXO1bwvyQ5zMO9JNiTZA9wDfJjJCuf+qvrqMvkeyT7sfwB44tomnliau6qOzPlrhjn/wyQbh7HjnvP1UBTz6NKquhh4IfCKJM9ZvLMm68O5eN3yPGUd/DFwPrAVuBv4/XHjTJfkdOAvgFdW1ZcW75v1eV8m+1zMe1UdrqqtwJOZrGy+Y+RIx2Rp7iQXAq9ikv+ZwBOA3zzR+18PRXEIeMqij588jM2sqjo0/HkP8H4mT8gvHln+DX/eM17Co5qWdeYfi6r64vCX6n+Bt/C10xwzlT3JqUx+0F5fVe8bhudi3pfLPi/zfkRV3Q98DHg2k1MzR34v3uJ8j2Qf9p8J3LfGUb/OotwvGE4DVlU9DLyNk5jz9VAU/wRsGV6ZcBqTi0ofGDnTVEm+MckZR7aBHwIOMMl85XDYlcBfjpPwmEzL+gHg54dXVTwLeGDRqZKZsORc7EuYzD1Msr9seCXLucAW4Ja1zgeTV6UAfwJ8uqr+YNGumZ/3adnnZN43JTlr2H4s8INMrrF8DLhiOGzpvB95PK4APjqs9NbUlNyfWfSPijC5rrJ4zo/v+TLGVfqVvjG5iv9ZJucTrxo7z1GynsfkVR57gduO5GVybvNvgTuAjwBPGDvrkOvdTE4V/A+Tc5m/OC0rk1dRXDM8DvuBbTOY/boh277hL8zmRcdfNWS/HXjhiLkvZXJaaR+wZ7i9aB7mvck+D/P+dOCfh4wHgFcP4+cxKa87gT8HNg7jjxk+vnPYf96M5f7oMOcHgHfxtVdGHffzxV/hIUlqrYdTT5KkVWRRSJJaFoUkqWVRSJJaFoUkqWVRSJJaFoUkqfV/Fr7IVlOu5dkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['class'].value_counts().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13fcb2990>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat([train_df, y_train], axis = 1).groupby('sex').survived.mean().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
    "                      'deck', 'embark_town', 'alone']\n",
    "numeric_columns = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column, vocab)\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                categorical_column, vocab)))\n",
    "for numeric_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(\n",
    "            numeric_column, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_df, label_df, epochs = 10, shuffle = True, batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train_df, y_train, batch_size =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': <tf.Tensor: id=38, shape=(5,), dtype=string, numpy=array([b'female', b'male', b'male', b'male', b'female'], dtype=object)>, 'age': <tf.Tensor: id=30, shape=(5,), dtype=float64, numpy=array([31.,  2., 28., 28., 58.])>, 'n_siblings_spouses': <tf.Tensor: id=36, shape=(5,), dtype=int32, numpy=array([0, 3, 0, 0, 0], dtype=int32)>, 'parch': <tf.Tensor: id=37, shape=(5,), dtype=int32, numpy=array([0, 1, 0, 0, 1], dtype=int32)>, 'fare': <tf.Tensor: id=35, shape=(5,), dtype=float64, numpy=array([  8.6833,  21.075 ,  10.5   ,   7.75  , 153.4625])>, 'class': <tf.Tensor: id=32, shape=(5,), dtype=string, numpy=array([b'Third', b'Third', b'Second', b'Third', b'First'], dtype=object)>, 'deck': <tf.Tensor: id=33, shape=(5,), dtype=string, numpy=array([b'unknown', b'unknown', b'unknown', b'unknown', b'C'], dtype=object)>, 'embark_town': <tf.Tensor: id=34, shape=(5,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Southampton', b'Southampton', b'Queenstown',\n",
      "       b'Southampton'], dtype=object)>, 'alone': <tf.Tensor: id=31, shape=(5,), dtype=string, numpy=array([b'y', b'n', b'y', b'y', b'n'], dtype=object)>} tf.Tensor([1 0 0 0 1], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset.take(1):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[28. ]\n",
      " [35. ]\n",
      " [26. ]\n",
      " [55.5]\n",
      " [25. ]]\n",
      "WARNING:tensorflow:Layer dense_features_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /Users/claire_liu/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4276: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /Users/claire_liu/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4331: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# keras.layers.DenseFeature\n",
    "for x, y in train_dataset.take(1):\n",
    "    age_column = feature_columns[7]\n",
    "    gender_column = feature_columns[0]\n",
    "    print(keras.layers.DenseFeatures(age_column)(x).numpy())\n",
    "    print(keras.layers.DenseFeatures(gender_column)(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[28.      1.      0.      0.      1.      0.      0.      0.      0.\n",
      "   0.      0.      1.      0.      0.      1.      0.      0.      0.\n",
      "  51.8625  1.      0.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      0.      1.    ]\n",
      " [24.      1.      0.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "  24.15    0.      0.      0.      0.      1.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [28.      0.      1.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      0.      1.      0.      0.\n",
      "   7.8958  0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [36.      0.      1.      0.      0.      1.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "  10.5     0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [24.      0.      1.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "   7.4958  0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]]\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset.take(1):\n",
    "    print(keras.layers.DenseFeatures(feature_columns)(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer = keras.optimizers.SGD(lr=0.01),\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sequential is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Train for 20 steps, validate for 8 steps\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 71ms/step - loss: 2.2833 - accuracy: 0.5828 - val_loss: 0.6981 - val_accuracy: 0.7031\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.9069 - accuracy: 0.6594 - val_loss: 0.6105 - val_accuracy: 0.6992\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.7368 - accuracy: 0.6266 - val_loss: 0.6182 - val_accuracy: 0.6328\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6355 - accuracy: 0.6484 - val_loss: 0.6235 - val_accuracy: 0.6875\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6414 - accuracy: 0.6641 - val_loss: 0.6057 - val_accuracy: 0.6875\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6358 - accuracy: 0.6703 - val_loss: 0.6054 - val_accuracy: 0.7109\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6679 - accuracy: 0.6453 - val_loss: 0.5978 - val_accuracy: 0.7031\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6339 - accuracy: 0.6750 - val_loss: 0.5909 - val_accuracy: 0.7031\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6001 - accuracy: 0.7047 - val_loss: 0.5860 - val_accuracy: 0.6953\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6198 - accuracy: 0.6734 - val_loss: 0.5804 - val_accuracy: 0.6953\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5926 - accuracy: 0.6734 - val_loss: 0.5935 - val_accuracy: 0.6992\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5955 - accuracy: 0.6922 - val_loss: 0.5813 - val_accuracy: 0.7188\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6090 - accuracy: 0.6859 - val_loss: 0.5990 - val_accuracy: 0.6758\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5956 - accuracy: 0.7000 - val_loss: 0.5752 - val_accuracy: 0.6836\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5767 - accuracy: 0.6828 - val_loss: 0.5737 - val_accuracy: 0.7031\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5720 - accuracy: 0.7078 - val_loss: 0.5754 - val_accuracy: 0.6953\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5952 - accuracy: 0.7063 - val_loss: 0.5778 - val_accuracy: 0.6836\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5800 - accuracy: 0.6687 - val_loss: 0.5728 - val_accuracy: 0.6797\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5885 - accuracy: 0.6875 - val_loss: 0.5779 - val_accuracy: 0.6875\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5803 - accuracy: 0.7172 - val_loss: 0.5884 - val_accuracy: 0.6992\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5665 - accuracy: 0.7047 - val_loss: 0.5898 - val_accuracy: 0.6758\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.5902 - accuracy: 0.6797 - val_loss: 0.5656 - val_accuracy: 0.7266\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6030 - accuracy: 0.6719 - val_loss: 0.5732 - val_accuracy: 0.6836\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5619 - accuracy: 0.6984 - val_loss: 0.5647 - val_accuracy: 0.6992\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5799 - accuracy: 0.7156 - val_loss: 0.5734 - val_accuracy: 0.6641\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5372 - accuracy: 0.7312 - val_loss: 0.5692 - val_accuracy: 0.7031\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5789 - accuracy: 0.7188 - val_loss: 0.5646 - val_accuracy: 0.6797\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5823 - accuracy: 0.7188 - val_loss: 0.5570 - val_accuracy: 0.6914\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.5549 - accuracy: 0.7141 - val_loss: 0.5488 - val_accuracy: 0.7109\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5947 - accuracy: 0.6812 - val_loss: 0.5562 - val_accuracy: 0.6914\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5321 - accuracy: 0.7266 - val_loss: 0.8220 - val_accuracy: 0.5742\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5725 - accuracy: 0.7188 - val_loss: 0.6152 - val_accuracy: 0.6523\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5792 - accuracy: 0.7234 - val_loss: 0.5597 - val_accuracy: 0.7109\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5514 - accuracy: 0.7437 - val_loss: 0.5902 - val_accuracy: 0.6797\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5655 - accuracy: 0.7250 - val_loss: 0.5357 - val_accuracy: 0.7148\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5485 - accuracy: 0.7328 - val_loss: 0.6994 - val_accuracy: 0.6367\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5709 - accuracy: 0.7094 - val_loss: 0.5373 - val_accuracy: 0.7031\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5628 - accuracy: 0.7172 - val_loss: 0.5545 - val_accuracy: 0.6914\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6060 - accuracy: 0.6969 - val_loss: 0.5488 - val_accuracy: 0.7148\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5544 - accuracy: 0.7359 - val_loss: 0.5742 - val_accuracy: 0.6680\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5389 - accuracy: 0.7297 - val_loss: 0.5290 - val_accuracy: 0.7266\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5614 - accuracy: 0.7109 - val_loss: 0.5482 - val_accuracy: 0.7109\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5530 - accuracy: 0.7219 - val_loss: 0.5305 - val_accuracy: 0.7227\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5441 - accuracy: 0.7406 - val_loss: 0.5408 - val_accuracy: 0.7266\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5807 - accuracy: 0.7172 - val_loss: 0.5347 - val_accuracy: 0.7344\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5379 - accuracy: 0.7391 - val_loss: 0.5283 - val_accuracy: 0.7383\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5665 - accuracy: 0.7141 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5389 - accuracy: 0.7531 - val_loss: 0.5259 - val_accuracy: 0.7305\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.5400 - accuracy: 0.7219 - val_loss: 0.5327 - val_accuracy: 0.7461\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5542 - accuracy: 0.7437 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5450 - accuracy: 0.7375 - val_loss: 0.5236 - val_accuracy: 0.7266\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5582 - accuracy: 0.7219 - val_loss: 0.5347 - val_accuracy: 0.7266\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5226 - accuracy: 0.7563 - val_loss: 0.5276 - val_accuracy: 0.7539\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5215 - accuracy: 0.7469 - val_loss: 0.5119 - val_accuracy: 0.7422\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5541 - accuracy: 0.7500 - val_loss: 0.7441 - val_accuracy: 0.6328\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5411 - accuracy: 0.7359 - val_loss: 0.5147 - val_accuracy: 0.7383\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5446 - accuracy: 0.7234 - val_loss: 0.5382 - val_accuracy: 0.7305\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5377 - accuracy: 0.7328 - val_loss: 0.5331 - val_accuracy: 0.7461\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5464 - accuracy: 0.7188 - val_loss: 0.5259 - val_accuracy: 0.7578\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5210 - accuracy: 0.7422 - val_loss: 0.5116 - val_accuracy: 0.7344\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4954 - accuracy: 0.7656 - val_loss: 0.5224 - val_accuracy: 0.7109\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5498 - accuracy: 0.7234 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5379 - accuracy: 0.7391 - val_loss: 0.5156 - val_accuracy: 0.7344\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5396 - accuracy: 0.7563 - val_loss: 0.6140 - val_accuracy: 0.6445\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5475 - accuracy: 0.7203 - val_loss: 0.5930 - val_accuracy: 0.7070\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5163 - accuracy: 0.7547 - val_loss: 0.5104 - val_accuracy: 0.7422\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5724 - accuracy: 0.7031 - val_loss: 0.5260 - val_accuracy: 0.7344\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5337 - accuracy: 0.7437 - val_loss: 0.5163 - val_accuracy: 0.7422\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5416 - accuracy: 0.7281 - val_loss: 0.8535 - val_accuracy: 0.5508\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5061 - accuracy: 0.7656 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7453 - val_loss: 0.5164 - val_accuracy: 0.7305\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5143 - accuracy: 0.7641 - val_loss: 0.5115 - val_accuracy: 0.7461\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5203 - accuracy: 0.7609 - val_loss: 0.5136 - val_accuracy: 0.7305\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5269 - accuracy: 0.7531 - val_loss: 0.6018 - val_accuracy: 0.6992\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5308 - accuracy: 0.7563 - val_loss: 0.5126 - val_accuracy: 0.7539\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5477 - accuracy: 0.7500 - val_loss: 0.5314 - val_accuracy: 0.7344\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5114 - accuracy: 0.7547 - val_loss: 0.6524 - val_accuracy: 0.6367\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5278 - accuracy: 0.7594 - val_loss: 0.7253 - val_accuracy: 0.6172\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5254 - accuracy: 0.7516 - val_loss: 0.4937 - val_accuracy: 0.7617\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5246 - accuracy: 0.7453 - val_loss: 0.5021 - val_accuracy: 0.7617\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5175 - accuracy: 0.7672 - val_loss: 0.6443 - val_accuracy: 0.6445\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5859 - accuracy: 0.7250 - val_loss: 0.5166 - val_accuracy: 0.7422\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5517 - accuracy: 0.7203 - val_loss: 0.5662 - val_accuracy: 0.7188\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5532 - accuracy: 0.7484 - val_loss: 0.5188 - val_accuracy: 0.7578\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5061 - accuracy: 0.7688 - val_loss: 0.5053 - val_accuracy: 0.7461\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5151 - accuracy: 0.7437 - val_loss: 0.5482 - val_accuracy: 0.7266\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5140 - accuracy: 0.7766 - val_loss: 0.4978 - val_accuracy: 0.7461\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5684 - accuracy: 0.7203 - val_loss: 0.5340 - val_accuracy: 0.7266\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5173 - accuracy: 0.7609 - val_loss: 0.5026 - val_accuracy: 0.7305\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5232 - accuracy: 0.7469 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4959 - accuracy: 0.7750 - val_loss: 0.5679 - val_accuracy: 0.7070\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5370 - accuracy: 0.7500 - val_loss: 0.5847 - val_accuracy: 0.7031\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5288 - accuracy: 0.7437 - val_loss: 0.4995 - val_accuracy: 0.7461\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5113 - accuracy: 0.7531 - val_loss: 0.4957 - val_accuracy: 0.7539\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5420 - accuracy: 0.7594 - val_loss: 0.5164 - val_accuracy: 0.7227\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5177 - accuracy: 0.7547 - val_loss: 0.6093 - val_accuracy: 0.7148\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.5673 - accuracy: 0.7266 - val_loss: 0.5156 - val_accuracy: 0.7344\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.5293 - accuracy: 0.7597 - val_loss: 0.6510 - val_accuracy: 0.6797\n",
      "Epoch 99/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
      " 0/20 [..............................] - ETA: 0s"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Empty training data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e909079895e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m history = model.fit(train_dataset,\n\u001b[1;32m      7\u001b[0m                    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                    steps_per_epoch=20, validation_steps=8, epochs=100)\n\u001b[0m",
      "\u001b[0;32m~/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m   \u001b[0;31m# End of an epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m   \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mfinalize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Empty training data.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Empty training data."
     ]
    }
   ],
   "source": [
    "# 1. model.fit\n",
    "# 2. model -> estimator -> train\n",
    "\n",
    "train_dataset = make_dataset(train_df, y_train, epochs = 100)\n",
    "eval_dataset = make_dataset(eval_df, y_eval, epochs=100, shuffle=False)\n",
    "history = model.fit(train_dataset,\n",
    "                   validation_data=eval_dataset,\n",
    "                   steps_per_epoch=20, validation_steps=8, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/wf/3x76jnjx33j846fn86w408c5jrgmwt/T/tmpfvpb6pdx\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
      "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/wf/3x76jnjx33j846fn86w408c5jrgmwt/T/tmpfvpb6pdx', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1484b9b10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /Users/claire_liu/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/claire_liu/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-42fed04eab11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_to_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# input_fn : 1. function 2. return a.(features, labels), dataset-> (feature, label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1158\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1188\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1190\u001b[0;31m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1191\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[0;32m~/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0mmodel_output_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;31m# We need to make sure that the output names of the last layer in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36m_clone_and_build_model\u001b[0;34m(mode, keras_model, custom_objects, features, labels, optimizer_config)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[0min_place_reset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0moptimizer_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m       optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msample_weight_tensors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36mclone_and_build_model\u001b[0;34m(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m       \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     if all([isinstance(clone, Sequential),\n",
      "\u001b[0;32m~/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    417\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     return _clone_sequential_model(\n\u001b[0;32m--> 419\u001b[0;31m         model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[1;32m    420\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     return _clone_functional_model(\n",
      "\u001b[0;32m~/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    336\u001b[0m       \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m       \u001b[0morigin_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    985\u001b[0m                         sparse_tensor.SparseTensor)):\n\u001b[1;32m    986\u001b[0m     raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) +\n\u001b[0;32m--> 987\u001b[0;31m                      '`. Expected a symbolic tensor instance.')\n\u001b[0m\u001b[1;32m    988\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance."
     ]
    }
   ],
   "source": [
    "estimator = keras.estimator.model_to_estimator(model)\n",
    "# input_fn : 1. function 2. return a.(features, labels), dataset-> (feature, label)\n",
    "estimator.train(input_fn = lambda: make_dataset(train_df, y_train, epochs=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_2.0_env",
   "language": "python",
   "name": "tensorflow_2.0_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
