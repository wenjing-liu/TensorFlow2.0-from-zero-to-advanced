{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=7, micro=4, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.2\n",
      "numpy 1.17.4\n",
      "pandas 0.25.3\n",
      "sklearn 0.22\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. loads data\n",
    "# 2. preprocesses data -> dataset\n",
    "# 3. tools\n",
    "# 3.1 generates position embedding\n",
    "# 3.2 create mask. (a. padding, b. decoder)\n",
    "# 3.3 scaled_dot_product_attention\n",
    "# 4. builds model\n",
    "# 4.1 MultiheadAttention\n",
    "# 4.2 EncoderLayer\n",
    "# 4.3 DecoderLayer\n",
    "# 4.4 EncoderModel\n",
    "# 4.5 DecoderModel\n",
    "# 4.6 Trnasformer\n",
    "# 5. optimizer & loss\n",
    "# 6. train step -> train\n",
    "# 7. Evaluate and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset ted_hrlr_translate (124.94 MiB) to /Users/claire_liu/tensorflow_datasets/ted_hrlr_translate/pt_to_en/0.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3e20066a934b07ba4d430e660713f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a17bcb50c0411fa309ed63bb9189f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf7f73111c547c8a227befd11050d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c6319963ba4b54835f580c67912bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99d5cd2b01d4d1e8a7cc055112edb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Shuffling...', max=1.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/claire_liu/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/claire_liu/Documents/Developer/TensorFlow2.0-from-zero-to-advanced/env/lib/python3.7/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6f68e7e33d49d492c50e57c77718ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Reading...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94745eb7d35742c48cb14f78d9768158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Writing...', max=51785.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9bfbde35a642408a1aef5813972b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b127168fbe4689ab8ac77d71e3d58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Shuffling...', max=1.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335b4ad0049246b0a0b3da52b499bd3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Reading...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a685581f864479b9dff1778778ed6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Writing...', max=1193.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9d2d0335ad4afda16656862073d84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2aafae22bd4e499c4fea1abf2a67cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Shuffling...', max=1.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30b42caf211462681f23f47a7d4a959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Reading...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e3fb05e2c44c27821ebc600518ed47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Writing...', max=1803.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset ted_hrlr_translate downloaded and prepared to /Users/claire_liu/tensorflow_datasets/ted_hrlr_translate/pt_to_en/0.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "tfds.core.DatasetInfo(\n",
      "    name='ted_hrlr_translate',\n",
      "    version=0.0.1,\n",
      "    description='Data sets derived from TED talk transcripts for comparing similar language pairs\n",
      "where one is high resource and the other is low resource.\n",
      "',\n",
      "    homepage='https://github.com/neulab/word-embeddings-for-nmt',\n",
      "    features=Translation({\n",
      "        'en': Text(shape=(), dtype=tf.string),\n",
      "        'pt': Text(shape=(), dtype=tf.string),\n",
      "    }),\n",
      "    total_num_examples=54781,\n",
      "    splits={\n",
      "        'test': 1803,\n",
      "        'train': 51785,\n",
      "        'validation': 1193,\n",
      "    },\n",
      "    supervised_keys=('pt', 'en'),\n",
      "    citation=\"\"\"@inproceedings{Ye2018WordEmbeddings,\n",
      "      author  = {Ye, Qi and Devendra, Sachan and Matthieu, Felix and Sarguna, Padmanabhan and Graham, Neubig},\n",
      "      title   = {When and Why are pre-trained word embeddings useful for Neural Machine Translation},\n",
      "      booktitle = {HLT-NAACL},\n",
      "      year    = {2018},\n",
      "      }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "examples, info = tfds.load('ted_hrlr_translate/pt_to_en',\n",
    "                          with_info = True,\n",
    "                          as_supervised = True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'os astr\\xc3\\xb3nomos acreditam que cada estrela da gal\\xc3\\xa1xia tem um planeta , e especulam que at\\xc3\\xa9 um quinto deles tem um planeta do tipo da terra que poder\\xc3\\xa1 ter vida , mas ainda n\\xc3\\xa3o vimos nenhum deles .'\n",
      "b\"astronomers now believe that every star in the galaxy has a planet , and they speculate that up to one fifth of them have an earth-like planet that might be able to harbor life , but we have n't seen any of them .\"\n",
      "\n",
      "b'o problema \\xc3\\xa9 que nunca vivi l\\xc3\\xa1 um \\xc3\\xbanico dia .'\n",
      "b\"except , i 've never lived one day of my life there .\"\n",
      "\n",
      "b'agora aqui temos imagens sendo extra\\xc3\\xaddas em tempo real diretamente do feed ,'\n",
      "b'now here are live images being pulled straight from the feed .'\n",
      "\n",
      "b'agora : um , dois , tr\\xc3\\xaas , vai .'\n",
      "b'so : one , two , three , go .'\n",
      "\n",
      "b'eventualmente , vamos ver se teremos todos os sentidos humanos empregues , e se vamos ter meios para viver a hist\\xc3\\xb3ria qualquer que seja a via escolhida .'\n",
      "b'eventually , we can see if we will have all of our human senses employed , and we will have agency to live the story in any path we choose .'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pt, en in train_examples.take(5):\n",
    "    print(pt.numpy())\n",
    "    print(en.numpy())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples),\n",
    "    target_vocab_size = 2 ** 13)\n",
    "pt_tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples),\n",
    "    target_vocab_size = 2 ** 13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799]\n",
      "Origin string is Transformer is awesome\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome'\n",
    "\n",
    "tokenized_string = en_tokenizer.encode(sample_string)\n",
    "print('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "origin_string = en_tokenizer.decode(tokenized_string)\n",
    "print('Origin string is {}'.format(origin_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7915 --> T\n",
      "1248 --> ran\n",
      "7946 --> s\n",
      "7194 --> former \n",
      "13 --> is \n",
      "2799 --> awesome\n"
     ]
    }
   ],
   "source": [
    "assert origin_string == sample_string\n",
    "\n",
    "for token in tokenized_string:\n",
    "    print('{} --> {}'.format(token, en_tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 20000\n",
    "batch_size = 64\n",
    "max_length = 40\n",
    "\n",
    "def encode_to_subword(pt_sentence, en_sentence):\n",
    "    pt_sequence = [pt_tokenizer.vocab_size] \\\n",
    "    + pt_tokenizer.encode(pt_sentence.numpy()) \\\n",
    "    + [pt_tokenizer.vocab_size + 1]\n",
    "    en_sequence = [en_tokenizer.vocab_size] \\\n",
    "    + en_tokenizer.encode(en_sentence.numpy()) \\\n",
    "    +[en_tokenizer.vocab_size + 1]\n",
    "    return pt_sequence, en_sequence\n",
    "\n",
    "def filter_by_max_length(pt, en):\n",
    "    return tf.logical_and(tf.size(pt) <= max_length,\n",
    "                         tf.size(en) <= max_length)\n",
    "\n",
    "def tf_encode_to_subword(pt_sentence, en_sentence):\n",
    "    return tf.py_function(encode_to_subword,\n",
    "                         [pt_sentence, en_sentence],\n",
    "                         [tf.int64, tf.int64])\n",
    "\n",
    "train_dataset = train_examples.map(tf_encode_to_subword)\n",
    "train_dataset = train_dataset.filter(filter_by_max_length)\n",
    "train_dataset = train_dataset.shuffle(\n",
    "    buffer_size).padded_batch(batch_size,\n",
    "                              padded_shapes=([-1], [-1]))\n",
    "\n",
    "valid_dataset = val_examples.map(tf_encode_to_subword)\n",
    "valid_dataset = valid_dataset.filter(\n",
    "    filter_by_max_length).padded_batch(batch_size,\n",
    "                                       padded_shapes=([-1], [-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 40) (64, 40)\n",
      "(64, 38) (64, 40)\n",
      "(64, 40) (64, 40)\n",
      "(64, 39) (64, 39)\n",
      "(64, 37) (64, 38)\n"
     ]
    }
   ],
   "source": [
    "for pt_batch, en_batch in valid_dataset.take(5):\n",
    "    print(pt_batch.shape, en_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "# PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\n",
    "# PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "\n",
    "# pos.shape: [sentence_length, 1]\n",
    "# i.shape: [1, d_model]\n",
    "# result.shape: [sentence_length, d_model]\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 *(i // 2)) / np.float(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def get_postion_embedding(sentence_length, d_model):\n",
    "    angle_rads =  get_angles(np.arange(sentence_length)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "    \n",
    "    # sines.shape: [sentence_length, d_model / 2]\n",
    "    # cosines.shape: [sentence_length, d_model / 2]\n",
    "    sines = np.sin(angle_rads[:, 0::2])\n",
    "    cosines = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    # position_embedding.shape: [sentence_length, d_model]\n",
    "    position_embedding = np.concatenate([sines, cosines], axis = -1)\n",
    "    # position_embedding.shape: [1, sentence_length, d_model]\n",
    "    position_embedding = position_embedding[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(position_embedding, dtype=tf.float32)\n",
    "\n",
    "position_embedding = get_postion_embedding(50, 512)\n",
    "print(position_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_position_embedding(position_embedding):\n",
    "    plt.pcolormesh(position_embedding[0], cmap='RdBu')\n",
    "    plt.xlabel('Depth')\n",
    "    plt.xlim(0, 512)\n",
    "    plt.ylabel('Position')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "plot_position_embedding(position_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=209064, shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. padding mask, 2. look ahead\n",
    "\n",
    "# batch_data.shape: [batch_size, seq_len]\n",
    "def create_padding_mask(batch_data):\n",
    "    padding_mask = tf.cast(tf.math.equal(batch_data, 0), tf.float32)\n",
    "    # [batch_size, 1, 1, seq_len]\n",
    "    return padding_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=209120, shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "create_look_ahead_mask(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - q: shape== (..., seq_len_q, depth)\n",
    "    - k: shape == (..., seq_len_k, depth)\n",
    "    - v: shape == (..., seq_len_v, depth_v)\n",
    "    - seq_len_k = seq_len_v\n",
    "    - mask shape == (..., seq_len_q, seq_len_k)\n",
    "    Returns:\n",
    "    - output: weighted sum\n",
    "    - attention_weights: weights of attention\n",
    "    \"\"\"\n",
    "    \n",
    "    # matmul_qk.shape: (..., seq_len_q, seq_len_ke)\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b = True)\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "    \n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis = -1)\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights\n",
    "\n",
    "def print_scaled_dot_product_attention(q, k, v):\n",
    "    temp_out, temp_att = scaled_dot_product_attention(q, k, v, None)\n",
    "    print(temp_att)\n",
    "    print(temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[8.4332744e-26 1.0000000e+00 8.4332744e-26 8.4332744e-26]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[1.000000e+01 9.276602e-25]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_k = tf.constant([[10, 0, 0],\n",
    "                      [0 ,10, 0],\n",
    "                      [0, 0, 10],\n",
    "                      [0, 0, 10]], dtype=tf.float32)\n",
    "temp_v = tf.constant([[1, 0],\n",
    "                      [10, 0],\n",
    "                      [100, 5],\n",
    "                      [1000, 6]], dtype=tf.float32)\n",
    "temp_q1 = tf.constant([[0, 10, 0]], dtype=tf.float32)\n",
    "print_scaled_dot_product_attention(temp_q1, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 60, 512) (1, 8, 60, 60)\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    q->Wq->Q->split->q0, q1, q2 ...\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert self.d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = self.d_model // self.num_heads\n",
    "        \n",
    "        self.WQ = keras.layers.Dense(self.d_model)\n",
    "        self.WK = keras.layers.Dense(self.d_model)\n",
    "        self.WV = keras.layers.Dense(self.d_model)\n",
    "        \n",
    "        self.dense = keras.layers.Dense(self.d_model)\n",
    "    \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, q, k , v, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q = self.WQ(q)\n",
    "        k = self.WK(k)\n",
    "        v = self.WV(v)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        \n",
    "        scaled_attention_ouputs, attention_weights = \\\n",
    "        scaled_dot_product_attention(q, k, v, mask)\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention_ouputs, (batch_size, -1, self.d_model))\n",
    "        \n",
    "        output = self.dense(concat_attention)\n",
    "        return output, attention_weights\n",
    "\n",
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 256))\n",
    "output, attn = temp_mha(y, y, y, mask=None)\n",
    "print(output.shape, attn.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feed_forward_network(d_model, dff):\n",
    "    return keras.Sequential([\n",
    "        keras.layers.Dense(dff, activation='relu'),\n",
    "        keras.layers.Dense(d_model)\n",
    "    ])\n",
    "\n",
    "sample_ffn = feed_forward_network(512, 2018)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "class EncoderLayer(keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layer_norm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layer_norm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layer_norm1(x + attn_output)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layer_norm2(out1 + ffn_output)\n",
    "        \n",
    "        return out2\n",
    "\n",
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "sample_input = tf.random.uniform((64, 50, 512))\n",
    "sample_output = sample_encoder_layer(sample_input, False, None)\n",
    "print(sample_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 60, 512) (64, 8, 60, 60) (64, 8, 60, 50)\n"
     ]
    }
   ],
   "source": [
    "class DecoderLayer(keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        \n",
    "        self.ffn = feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layer_norm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layer_norm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layer_norm3 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "        self.dropout3 = keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, encoding_outputs, training, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layer_norm1(attn1 + x)\n",
    "        \n",
    "        attn2, attn_weights2 = self.mha2(out1, encoding_outputs, encoding_outputs, padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layer_norm2(attn2 + out1)\n",
    "        \n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layer_norm3(ffn_output + out2)\n",
    "        \n",
    "        return out3, attn_weights1, attn_weights2\n",
    "\n",
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "sample_decoder_input = tf.random.uniform((64, 60, 512))\n",
    "sample_decoder_output, sample_decoder_weight1, sample_decoder_weight2 = sample_decoder_layer(\n",
    "    sample_decoder_input, sample_output, False, None, None)\n",
    "print(sample_decoder_output.shape, sample_decoder_weight1.shape, sample_decoder_weight2.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 37, 512)\n"
     ]
    }
   ],
   "source": [
    "class EncoderModel(keras.layers.Layer):\n",
    "    def __init__(self, num_layers, input_vocab_size, max_length, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(input_vocab_size, self.d_model)\n",
    "        self.position_embedding = get_postion_embedding(max_length, self.d_model)\n",
    "        \n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        self.encoding_layers = [\n",
    "            EncoderLayer(d_model, num_heads, dff, rate) for _ in range(self.num_layers)\n",
    "        ]\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        input_seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.position_embedding[:, :input_seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.encoding_layers[i](x, training, mask)\n",
    "        \n",
    "        return x\n",
    "\n",
    "sample_encoder_model = EncoderModel(2, 8500, max_length, 512, 8, 2048)\n",
    "sample_encoder_model_input = tf.random.uniform((64, 37))\n",
    "sample_encoder_model_output = sample_encoder_model(sample_encoder_model_input, False, mask=None)\n",
    "print(sample_encoder_model_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 35, 512)\n",
      "(64, 8, 35, 35)\n",
      "(64, 8, 35, 37)\n",
      "(64, 8, 35, 35)\n",
      "(64, 8, 35, 37)\n"
     ]
    }
   ],
   "source": [
    "class DecoderModel(keras.layers.Layer):\n",
    "    def __init__(self, num_layers, target_vocab_size, max_length, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.max_length = max_length\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.embedding = keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.position_embedding = get_postion_embedding(max_length, d_model)\n",
    "        \n",
    "        self.dropout = keras.layers.Dropout(rate)\n",
    "        self.decoder_layers = [\n",
    "            DecoderLayer(d_model, num_heads, dff, rate) for _ in range(self.num_layers)\n",
    "        ]\n",
    "    \n",
    "    def call(self, x, encoding_outputs, training, look_ahead_mask, padding_mask):\n",
    "        output_seq_len = tf.shape(x)[1]\n",
    "        assert output_seq_len <= self.max_length\n",
    "        \n",
    "        attention_weights = {}\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x *=tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.position_embedding[:, :output_seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training = training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x, att1, att2 = self.decoder_layers[i](x, encoding_outputs,\n",
    "                                                   training, look_ahead_mask,\n",
    "                                                   padding_mask)\n",
    "            attention_weights['decoder_layer{}_att1'.format(i+1)] = att1\n",
    "            attention_weights['decoder_layer{}_att2'.format(i+1)] = att2\n",
    "        \n",
    "        return x, attention_weights\n",
    "\n",
    "sample_decoder_model = DecoderModel(2, 8000, max_length, 512, 8, 2048)\n",
    "\n",
    "sampel_decoder_model_input = tf.random.uniform((64, 35))\n",
    "sample_decoder_model_output, sample_decoder_model_att = sample_decoder_model(sampel_decoder_model_input,\n",
    "                                                                                sample_encoder_model_output,\n",
    "                                                                                training=False,\n",
    "                                                                                look_ahead_mask=None,\n",
    "                                                                                padding_mask=None)\n",
    "print(sample_decoder_model_output.shape)\n",
    "for key in sample_decoder_model_att:\n",
    "    print(sample_decoder_model_att[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 31, 800)\n",
      "decoder_layer1_att1 (64, 8, 31, 31)\n",
      "decoder_layer1_att2 (64, 8, 31, 26)\n",
      "decoder_layer2_att1 (64, 8, 31, 31)\n",
      "decoder_layer2_att2 (64, 8, 31, 26)\n"
     ]
    }
   ],
   "source": [
    "class Transformer(keras.Model):\n",
    "    def __init__(self, num_layers, input_vocab_size, target_vocab_size,\n",
    "               max_length, d_model, num_heads, dff, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.encoder_model = EncoderModel(num_layers,\n",
    "                                         input_vocab_size,\n",
    "                                         max_length,\n",
    "                                         d_model,\n",
    "                                         num_heads,\n",
    "                                         dff,\n",
    "                                         rate)\n",
    "        self.decoder_model = DecoderModel(num_layers,\n",
    "                                         target_vocab_size,\n",
    "                                         max_length,\n",
    "                                         d_model,\n",
    "                                         num_heads,\n",
    "                                         dff,\n",
    "                                         rate)\n",
    "        self.final_layer = keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, encoder_padding_mask, look_ahead_mask, decoder_padding_mask):\n",
    "        encoding_outputs = self.encoder_model(inp, training, encoder_padding_mask)\n",
    "        decoding_outputs, attention_weights = self.decoder_model(tar, encoding_outputs,\n",
    "                                                                 training,\n",
    "                                                                 look_ahead_mask,\n",
    "                                                                 decoder_padding_mask)\n",
    "        predictions = self.final_layer(decoding_outputs)\n",
    "        \n",
    "        return predictions, attention_weights\n",
    "\n",
    "sampel_transformer = Transformer(2, 8500, 800, max_length, 512, 8, 2048, 0.1)\n",
    "temp_input = tf.random.uniform((64, 26))\n",
    "temp_target = tf.random.uniform((64, 31))\n",
    "\n",
    "predictions, attention_weights = sampel_transformer(temp_input, temp_target, training=False,\n",
    "                                                   encoder_padding_mask=None,\n",
    "                                                   look_ahead_mask=None,\n",
    "                                                   decoder_padding_mask=None)\n",
    "print(predictions.shape)\n",
    "\n",
    "for key in attention_weights:\n",
    "    print(key, attention_weights[key].shape)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_2.0_env",
   "language": "python",
   "name": "tensorflow_2.0_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
