{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=7, micro=4, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.2\n",
      "numpy 1.17.4\n",
      "pandas 0.25.3\n",
      "sklearn 0.22\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8) (11610,)\n",
      "(3870, 8) (3870,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state = 7)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_all, y_train_all, random_state = 11)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# metric 使用\n",
    "metric = keras.metrics.MeanSquaredError()\n",
    "print(metric([5.], [2.]))\n",
    "print(metric([0.], [1.]))\n",
    "print(metric.result())\n",
    "metric.reset_states()\n",
    "metric([1.], [3.])\n",
    "print(metric.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 0 train mse: 4.07309875 train mse: 7.642049\t valid mse:  1.4308480100507164\n",
      "Epoch 1 train mse: 1.3147889 train mse: 1.2881663 train mse: 1.32380021.3204342\t valid mse:  1.3979405444234152\n",
      "Epoch 2 train mse: 1.4893204\t valid mse:  1.5539258794371715\n",
      "Epoch 3 train mse: 1.34565353\t valid mse:  1.4604544886579436\n",
      "Epoch 4 train mse: 1.3108404\t valid mse:  1.3992810170078682\n",
      "Epoch 5 train mse: 1.3143591\t valid mse:  1.3916753111825744\n",
      "Epoch 6 train mse: 1.2833709\t valid mse:  1.3952652894668651\n",
      "Epoch 7 train mse: 1.2908598\t valid mse:  1.3894684607436052\n",
      "Epoch 8 train mse: 1.2950555\t valid mse:  1.3861979057986047\n",
      "Epoch 9 train mse: 1.2731512\t valid mse:  1.387923006775714\n",
      "Epoch 10 train mse: 1.2989072\t valid mse:  1.3859415485992417\n",
      "Epoch 11 train mse: 1.2862943\t valid mse:  1.3951370590191106\n",
      "Epoch 12 train mse: 1.2774028 train mse: 1.2756554\t valid mse:  1.3850420245354869\n",
      "Epoch 13 train mse: 1.2583717\t valid mse:  1.385027208296278\n",
      "Epoch 14 train mse: 1.285264\t valid mse:  1.3842517258148\n",
      "Epoch 15 train mse: 1.2624539\t valid mse:  1.3931078399420345\n",
      "Epoch 16 train mse: 1.2331147\t valid mse:  1.3879077984896335\n",
      "Epoch 17 train mse: 1.2697992\t valid mse:  1.3838602188289253\n",
      "Epoch 18 train mse: 1.2454274 train mse: 1.2373441\t valid mse:  1.3842403508093404\n",
      "Epoch 19 train mse: 1.2688562\t valid mse:  1.3867299891734424e: 1.2715333\n",
      "Epoch 20 train mse: 1.2381865\t valid mse:  1.385389214797409\n",
      "Epoch 21 train mse: 1.2646192\t valid mse:  1.3846101025110102\n",
      "Epoch 22 train mse: 1.2830836\t valid mse:  1.3831658616588074\n",
      "Epoch 23 train mse: 1.2449543\t valid mse:  1.3863176152194696\n",
      "Epoch 24 train mse: 1.2756784\t valid mse:  1.385888000600074\n",
      "Epoch 25 train mse: 1.2509916 train mse: 1.2774549\t valid mse:  1.387670096321633\n",
      "Epoch 26 train mse: 1.2392093\t valid mse:  1.3832520248782063\n",
      "Epoch 27 train mse: 1.2425495\t valid mse:  1.3918007406440362\n",
      "Epoch 28 train mse: 1.2630758 28 train mse: 1.2472128\t valid mse:  1.3843539619703926\n",
      "Epoch 29 train mse: 1.2833644\t valid mse:  1.3843788671966137\n",
      "Epoch 30 train mse: 1.2416317\t valid mse:  1.3852444962683887\n",
      "Epoch 31 train mse: 1.2803704\t valid mse:  1.3852259319446738\n",
      "Epoch 32 train mse: 1.25012524train mse: 1.244549\t valid mse:  1.3856380884810826\n",
      "Epoch 33 train mse: 1.2930406\t valid mse:  1.3829529033028383\n",
      "Epoch 34 train mse: 1.2578366 train mse: 1.2503436\t valid mse:  1.3837500168089565\n",
      "Epoch 35 train mse: 1.2828242\t valid mse:  1.383426250114562\n",
      "Epoch 36 train mse: 1.2338841\t valid mse:  1.3895256944847476\n",
      "Epoch 37 train mse: 1.2678174\t valid mse:  1.385118689948165\n",
      "Epoch 38 train mse: 1.2542417\t valid mse:  1.38571574820589\n",
      "Epoch 39 train mse: 1.24892386\t valid mse:  1.383327535096414\n",
      "Epoch 40 train mse: 1.2700989\t valid mse:  1.3850483129362103\n",
      "Epoch 41 train mse: 1.259826\t valid mse:  1.3843129226122808\n",
      "Epoch 42 train mse: 1.2761211\t valid mse:  1.3833939147311436: 1.2838116\n",
      "Epoch 43 train mse: 1.2694606\t valid mse:  1.3850565939716664\n",
      "Epoch 44 train mse: 1.2651383 44 train mse: 1.4484869\t valid mse:  1.4010121030066025\n",
      "Epoch 45 train mse: 1.2818305\t valid mse:  1.3836591942219796\n",
      "Epoch 46 train mse: 1.2789981\t valid mse:  1.3837904227213196\n",
      "Epoch 47 train mse: 1.2592858train mse: 1.2801933\t valid mse:  1.3868738298575323\n",
      "Epoch 48 train mse: 1.2715876\t valid mse:  1.384252001392944\n",
      "Epoch 49 train mse: 1.2199879\t valid mse:  1.387046283923795451\n",
      "Epoch 50 train mse: 1.2660923\t valid mse:  1.384583821228728\n",
      "Epoch 51 train mse: 1.2808882 train mse: 1.2618833\t valid mse:  1.3829279591842283\n",
      "Epoch 52 train mse: 1.2842277\t valid mse:  1.383715976408186\n",
      "Epoch 53 train mse: 1.2672188\t valid mse:  1.384991333834843\n",
      "Epoch 54 train mse: 1.2300316\t valid mse:  1.3887659393097391\n",
      "Epoch 55 train mse: 1.2739078\t valid mse:  1.387011519449427\n",
      "Epoch 56 train mse: 1.2721205\t valid mse:  1.3842037257980564\n",
      "Epoch 57 train mse: 1.2669033\t valid mse:  1.385162650787496\n",
      "Epoch 58 train mse: 1.2460479\t valid mse:  1.382891743505978\n",
      "Epoch 59 train mse: 1.2804158\t valid mse:  1.3825616447752447\n",
      "Epoch 60 train mse: 1.2894415\t valid mse:  1.387078301420669\n",
      "Epoch 61 train mse: 1.2435704\t valid mse:  1.3832265793072576\n",
      "Epoch 62 train mse: 1.259412562 train mse: 1.2706172\t valid mse:  1.3827770422431707\n",
      "Epoch 63 train mse: 1.275796263 train mse: 1.2735635\t valid mse:  1.382901057529592\n",
      "Epoch 64 train mse: 1.2575418\t valid mse:  1.3893411527105217\n",
      "Epoch 65 train mse: 1.2213609\t valid mse:  1.384447776475987\n",
      "Epoch 66 train mse: 1.2667667\t valid mse:  1.3825517025239218\n",
      "Epoch 67 train mse: 1.2583585\t valid mse:  1.3830667226876001\n",
      "Epoch 68 train mse: 1.2720808\t valid mse:  1.3827155215270193\n",
      "Epoch 69 train mse: 1.2593399\t valid mse:  1.3854590009299579\n",
      "Epoch 70 train mse: 1.2221099\t valid mse:  1.3942072428304408\n",
      "Epoch 71 train mse: 1.2741393 71 train mse: 1.2715157\t valid mse:  1.3835530250190764\n",
      "Epoch 72 train mse: 1.2811079\t valid mse:  1.385673073708651\n",
      "Epoch 73 train mse: 1.25742535\t valid mse:  1.383801258569055\n",
      "Epoch 74 train mse: 1.2584224\t valid mse:  1.384747198692929\n",
      "Epoch 75 train mse: 1.2629646\t valid mse:  1.3838059672729168\n",
      "Epoch 76 train mse: 1.2591761\t valid mse:  1.3865906820264668\n",
      "Epoch 77 train mse: 1.2416648\t valid mse:  1.3833784724932516\n",
      "Epoch 78 train mse: 1.26227774\t valid mse:  1.382594678873941\n",
      "Epoch 79 train mse: 1.2820269\t valid mse:  1.3889093856428338\n",
      "Epoch 80 train mse: 1.2450024\t valid mse:  1.3824043435360598\n",
      "Epoch 81 train mse: 1.2735877\t valid mse:  1.38251170628125\n",
      "Epoch 82 train mse: 1.2709615\t valid mse:  1.3846868704293893\n",
      "Epoch 83 train mse: 1.2471534\t valid mse:  1.3862424629656172\n",
      "Epoch 84 train mse: 1.2421802\t valid mse:  1.3908542766360759\n",
      "Epoch 85 train mse: 1.2860371\t valid mse:  1.3863000048510954\n",
      "Epoch 86 train mse: 1.2265013\t valid mse:  1.3827649791052115\n",
      "Epoch 87 train mse: 1.2894603\t valid mse:  1.3832314230398812\n",
      "Epoch 88 train mse: 1.2504319 train mse: 1.3295014\t valid mse:  1.3858492511478004\n",
      "Epoch 89 train mse: 1.2535161\t valid mse:  1.3834153697026386\n",
      "Epoch 90 train mse: 1.2478249\t valid mse:  1.3864708251827935\n",
      "Epoch 91 train mse: 1.277286\t valid mse:  1.3855939659012582\n",
      "Epoch 92 train mse: 1.2663336\t valid mse:  1.384203763748191\n",
      "Epoch 93 train mse: 1.2546672\t valid mse:  1.386333926283122\n",
      "Epoch 94 train mse: 1.2727844\t valid mse:  1.383302358944558\n",
      "Epoch 95 train mse: 1.274893\t valid mse:  1.382601596607111\n",
      "Epoch 96 train mse: 1.2694072\t valid mse:  1.3827078642827642\n",
      "Epoch 97 train mse: 1.2665836\t valid mse:  1.3882256877166705\n",
      "Epoch 98 train mse: 1.2795285\t valid mse:  1.383523628937828\n",
      "Epoch 99 train mse: 1.2514524\t valid mse:  1.3860077733940848\n"
     ]
    }
   ],
   "source": [
    "# 1. batch 遍历训练集 metric\n",
    "#   1.1 自动求导\n",
    "# 2. epoch 结束 验证 metric\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "steps_per_epoch = len(x_train_scaled) // batch_size\n",
    "optimizer = keras.optimizers.SGD()\n",
    "metric = keras.metrics.MeanSquaredError()\n",
    "\n",
    "def random_batch(x, y, batch_size = 32):\n",
    "    idx = np.random.randint(0, len(x), size = batch_size)\n",
    "    return x[idx], y[idx]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    metric.reset_states()\n",
    "    for step in range(steps_per_epoch):\n",
    "        x_batch, y_batch = random_batch(x_train_scaled, y_train, batch_size)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch)\n",
    "            loss = tf.reduce_mean(keras.losses.mean_squared_error(y_batch, y_pred))\n",
    "            metric(y_pred, y_batch)\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        grads_and_vars = zip(grads, model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars)\n",
    "        print('\\rEpoch', epoch, 'train mse:', metric.result().numpy(), end='')\n",
    "    y_valid_pred = model(x_valid_scaled)\n",
    "    valid_loss = tf.reduce_mean(keras.losses.mean_squared_error(y_valid_pred, y_valid))\n",
    "    print('\\t', 'valid mse: ', valid_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_2.0_env",
   "language": "python",
   "name": "tensorflow_2.0_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
